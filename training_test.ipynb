{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from training_utils import *\n",
    "import torch\n",
    "import numpy as np\n",
    "from network_utils import *\n",
    "\n",
    "device = 'cuda:2'\n",
    "dataset = 'mnist'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'mnist':\n",
    "    test_dl = load_mnist(batch_size = 128, train = False)\n",
    "    train_dl = load_mnist(batch_size = 128, train = True)\n",
    "elif dataset == 'cifar10':\n",
    "    test_dl = load_cifar10(batch_size = 128, train = False)\n",
    "    train_dl = load_cifar10(batch_size = 128, train = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == 'mnist':\n",
    "    model = model_cnn_2layer(1, 28, 1).to(device)\n",
    "    model = initialize_weights(model)\n",
    "    model_sabr = model_cnn_2layer(1, 28, 1).to(device)\n",
    "    model_sabr = initialize_weights(model_sabr)\n",
    "elif dataset == 'cifar10':\n",
    "    model = model_cnn_2layer(3, 32, 1).to(device)\n",
    "    model = initialize_weights(model)\n",
    "    model_sabr = model_cnn_2layer(3, 32, 1).to(device)\n",
    "    model_sabr = initialize_weights(model_sabr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.8125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(test_dl))\n",
    "x, y = x.to(device), y.to(device)\n",
    "batch_accuracy(model, x, y, device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.3406, Acc: 89.83%, Verified: 0.00%\n",
      "  Val   - Loss: 0.1503, Acc: 95.32%, Verified: 0.00%\n",
      "Epoch 2/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.1125, Acc: 96.58%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0947, Acc: 96.93%, Verified: 0.00%\n",
      "Epoch 3/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.0794, Acc: 97.59%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0659, Acc: 97.95%, Verified: 0.00%\n",
      "Epoch 4/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.0651, Acc: 97.94%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0682, Acc: 97.85%, Verified: 0.00%\n",
      "Epoch 5/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.0545, Acc: 98.29%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0573, Acc: 98.21%, Verified: 0.00%\n",
      "Epoch 6/30, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.0447, Acc: 98.58%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0616, Acc: 98.18%, Verified: 0.00%\n",
      "Epoch 7/30, ε=0.01200, IBP Weight=0.04\n",
      "  Train - Loss: 0.5606, Acc: 97.26%, Verified: 53.30%\n",
      "  Val   - Loss: 4.3699, Acc: 97.87%, Verified: 0.00%\n",
      "Epoch 8/30, ε=0.02400, IBP Weight=0.08\n",
      "  Train - Loss: 0.2335, Acc: 98.50%, Verified: 67.93%\n",
      "  Val   - Loss: 10.2544, Acc: 98.55%, Verified: 0.00%\n",
      "Epoch 9/30, ε=0.03600, IBP Weight=0.12\n",
      "  Train - Loss: 0.2588, Acc: 98.82%, Verified: 72.07%\n",
      "  Val   - Loss: 14.5089, Acc: 98.63%, Verified: 0.00%\n",
      "Epoch 10/30, ε=0.04800, IBP Weight=0.16\n",
      "  Train - Loss: 0.2868, Acc: 98.97%, Verified: 73.40%\n",
      "  Val   - Loss: 17.3425, Acc: 98.69%, Verified: 0.00%\n",
      "Epoch 11/30, ε=0.06000, IBP Weight=0.20\n",
      "  Train - Loss: 0.3110, Acc: 99.08%, Verified: 73.91%\n",
      "  Val   - Loss: 20.3700, Acc: 98.63%, Verified: 0.00%\n",
      "Epoch 12/30, ε=0.07200, IBP Weight=0.24\n",
      "  Train - Loss: 0.3431, Acc: 99.07%, Verified: 73.78%\n",
      "  Val   - Loss: 22.7568, Acc: 98.62%, Verified: 0.00%\n",
      "Epoch 13/30, ε=0.08400, IBP Weight=0.28\n",
      "  Train - Loss: 0.3623, Acc: 99.04%, Verified: 74.28%\n",
      "  Val   - Loss: 25.4585, Acc: 98.53%, Verified: 0.00%\n",
      "Epoch 14/30, ε=0.09600, IBP Weight=0.32\n",
      "  Train - Loss: 0.3823, Acc: 99.06%, Verified: 74.55%\n",
      "  Val   - Loss: 26.4476, Acc: 98.61%, Verified: 0.00%\n",
      "Epoch 15/30, ε=0.10800, IBP Weight=0.36\n",
      "  Train - Loss: 0.3773, Acc: 98.98%, Verified: 76.33%\n",
      "  Val   - Loss: 24.7266, Acc: 98.60%, Verified: 0.00%\n",
      "Epoch 16/30, ε=0.12000, IBP Weight=0.40\n",
      "  Train - Loss: 0.3821, Acc: 98.95%, Verified: 77.38%\n",
      "  Val   - Loss: 25.9037, Acc: 98.55%, Verified: 0.00%\n",
      "Epoch 17/30, ε=0.13200, IBP Weight=0.44\n",
      "  Train - Loss: 0.4103, Acc: 98.97%, Verified: 77.47%\n",
      "  Val   - Loss: 29.6457, Acc: 98.67%, Verified: 0.00%\n",
      "Epoch 18/30, ε=0.14400, IBP Weight=0.48\n",
      "  Train - Loss: 0.4504, Acc: 98.97%, Verified: 76.61%\n",
      "  Val   - Loss: 31.0299, Acc: 98.58%, Verified: 0.00%\n",
      "Epoch 19/30, ε=0.15600, IBP Weight=0.52\n",
      "  Train - Loss: 0.4965, Acc: 98.92%, Verified: 75.53%\n",
      "  Val   - Loss: 32.5725, Acc: 98.54%, Verified: 0.00%\n",
      "Epoch 20/30, ε=0.16800, IBP Weight=0.56\n",
      "  Train - Loss: 0.5471, Acc: 98.89%, Verified: 74.67%\n",
      "  Val   - Loss: 35.5596, Acc: 98.28%, Verified: 0.00%\n",
      "Epoch 21/30, ε=0.18000, IBP Weight=0.60\n",
      "  Train - Loss: 0.6033, Acc: 98.86%, Verified: 73.45%\n",
      "  Val   - Loss: 37.4894, Acc: 98.35%, Verified: 0.00%\n",
      "Epoch 22/30, ε=0.19200, IBP Weight=0.64\n",
      "  Train - Loss: 0.6608, Acc: 98.84%, Verified: 72.30%\n",
      "  Val   - Loss: 41.2485, Acc: 98.40%, Verified: 0.00%\n",
      "Epoch 23/30, ε=0.20400, IBP Weight=0.68\n",
      "  Train - Loss: 0.7142, Acc: 98.74%, Verified: 71.82%\n",
      "  Val   - Loss: 47.0955, Acc: 98.35%, Verified: 0.00%\n",
      "Epoch 24/30, ε=0.21600, IBP Weight=0.72\n",
      "  Train - Loss: 0.7615, Acc: 98.66%, Verified: 71.70%\n",
      "  Val   - Loss: 55.4619, Acc: 98.22%, Verified: 0.00%\n",
      "Epoch 25/30, ε=0.22800, IBP Weight=0.76\n",
      "  Train - Loss: 0.8168, Acc: 98.62%, Verified: 71.09%\n",
      "  Val   - Loss: 58.6769, Acc: 98.38%, Verified: 0.00%\n",
      "Epoch 26/30, ε=0.24000, IBP Weight=0.80\n",
      "  Train - Loss: 0.8601, Acc: 98.55%, Verified: 70.62%\n",
      "  Val   - Loss: 61.5870, Acc: 97.99%, Verified: 0.00%\n",
      "Epoch 27/30, ε=0.25200, IBP Weight=0.84\n",
      "  Train - Loss: 0.9052, Acc: 98.49%, Verified: 70.40%\n",
      "  Val   - Loss: 64.9042, Acc: 98.02%, Verified: 0.00%\n",
      "Epoch 28/30, ε=0.26400, IBP Weight=0.88\n",
      "  Train - Loss: 0.9364, Acc: 98.41%, Verified: 70.66%\n",
      "  Val   - Loss: 66.0847, Acc: 98.09%, Verified: 0.00%\n",
      "Epoch 29/30, ε=0.27600, IBP Weight=0.92\n",
      "  Train - Loss: 0.9711, Acc: 98.35%, Verified: 70.42%\n",
      "  Val   - Loss: 67.5362, Acc: 97.94%, Verified: 0.00%\n",
      "Epoch 30/30, ε=0.28800, IBP Weight=0.96\n",
      "  Train - Loss: 1.0010, Acc: 98.19%, Verified: 70.94%\n",
      "  Val   - Loss: 70.7914, Acc: 97.79%, Verified: 0.00%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Sequential(\n",
       "   (0): Conv2d(1, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "   (1): ReLU()\n",
       "   (2): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "   (3): ReLU()\n",
       "   (4): Flatten(start_dim=1, end_dim=-1)\n",
       "   (5): Linear(in_features=392, out_features=128, bias=True)\n",
       "   (6): ReLU()\n",
       "   (7): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (8): ReLU()\n",
       "   (9): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (10): ReLU()\n",
       "   (11): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (12): ReLU()\n",
       "   (13): Linear(in_features=128, out_features=128, bias=True)\n",
       "   (14): ReLU()\n",
       "   (15): Linear(in_features=128, out_features=10, bias=True)\n",
       " ),\n",
       " {'train_loss': [0.34061237788200377,\n",
       "   0.11252906142075857,\n",
       "   0.07936288409233093,\n",
       "   0.06510738358100256,\n",
       "   0.054484053267041845,\n",
       "   0.04470475058456262,\n",
       "   0.5605662957072258,\n",
       "   0.23354793003400168,\n",
       "   0.25880225746631624,\n",
       "   0.2867673919439316,\n",
       "   0.310977764749527,\n",
       "   0.343137414709727,\n",
       "   0.3622671179612478,\n",
       "   0.38225734712282816,\n",
       "   0.3772923659880956,\n",
       "   0.3820593444188436,\n",
       "   0.4102613975842794,\n",
       "   0.4504230518976847,\n",
       "   0.4964938575426737,\n",
       "   0.5471375694910685,\n",
       "   0.6033110386530558,\n",
       "   0.6607731677055358,\n",
       "   0.7141834560712178,\n",
       "   0.7614515096346537,\n",
       "   0.8168413304011027,\n",
       "   0.8601155590375265,\n",
       "   0.9052031926155091,\n",
       "   0.936377961508433,\n",
       "   0.9711214813232422,\n",
       "   1.0010136699358623],\n",
       "  'train_acc': [89.83333333333333,\n",
       "   96.57833333333333,\n",
       "   97.58833333333334,\n",
       "   97.945,\n",
       "   98.29166666666667,\n",
       "   98.575,\n",
       "   97.26333333333334,\n",
       "   98.49833333333333,\n",
       "   98.81833333333333,\n",
       "   98.96833333333333,\n",
       "   99.07666666666667,\n",
       "   99.06666666666666,\n",
       "   99.04166666666667,\n",
       "   99.065,\n",
       "   98.985,\n",
       "   98.955,\n",
       "   98.975,\n",
       "   98.97,\n",
       "   98.92333333333333,\n",
       "   98.89,\n",
       "   98.86,\n",
       "   98.83666666666667,\n",
       "   98.73666666666666,\n",
       "   98.655,\n",
       "   98.61833333333334,\n",
       "   98.55166666666666,\n",
       "   98.48666666666666,\n",
       "   98.40833333333333,\n",
       "   98.35333333333334,\n",
       "   98.18666666666667],\n",
       "  'val_loss': [0.15026370791196822,\n",
       "   0.09470689749494195,\n",
       "   0.06588714339360595,\n",
       "   0.06815657755685971,\n",
       "   0.057318603259418156,\n",
       "   0.06160109335684683,\n",
       "   4.36986865234375,\n",
       "   10.254379489135742,\n",
       "   14.508897276306152,\n",
       "   17.34245136413574,\n",
       "   20.369977487182616,\n",
       "   22.756839721679686,\n",
       "   25.458466510009767,\n",
       "   26.447635485839843,\n",
       "   24.72657105102539,\n",
       "   25.903717236328124,\n",
       "   29.645655224609374,\n",
       "   31.0298852722168,\n",
       "   32.57254268188476,\n",
       "   35.5596143951416,\n",
       "   37.48936737060547,\n",
       "   41.24853721923828,\n",
       "   47.095522534179686,\n",
       "   55.46194833984375,\n",
       "   58.67693223876953,\n",
       "   61.58695731811523,\n",
       "   64.90422792358399,\n",
       "   66.0847171081543,\n",
       "   67.53622197265625,\n",
       "   70.79143267822266],\n",
       "  'val_acc': [95.32,\n",
       "   96.93,\n",
       "   97.95,\n",
       "   97.85,\n",
       "   98.21,\n",
       "   98.18,\n",
       "   97.87,\n",
       "   98.55,\n",
       "   98.63,\n",
       "   98.69,\n",
       "   98.63,\n",
       "   98.62,\n",
       "   98.53,\n",
       "   98.61,\n",
       "   98.6,\n",
       "   98.55,\n",
       "   98.67,\n",
       "   98.58,\n",
       "   98.54,\n",
       "   98.28,\n",
       "   98.35,\n",
       "   98.4,\n",
       "   98.35,\n",
       "   98.22,\n",
       "   98.38,\n",
       "   97.99,\n",
       "   98.02,\n",
       "   98.09,\n",
       "   97.94,\n",
       "   97.79],\n",
       "  'train_verified_acc': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   53.29666666666667,\n",
       "   67.92833333333333,\n",
       "   72.06666666666666,\n",
       "   73.39833333333333,\n",
       "   73.91,\n",
       "   73.785,\n",
       "   74.285,\n",
       "   74.54666666666667,\n",
       "   76.33333333333333,\n",
       "   77.38166666666666,\n",
       "   77.47,\n",
       "   76.605,\n",
       "   75.535,\n",
       "   74.675,\n",
       "   73.455,\n",
       "   72.30333333333333,\n",
       "   71.82166666666667,\n",
       "   71.705,\n",
       "   71.09166666666667,\n",
       "   70.61666666666666,\n",
       "   70.40333333333334,\n",
       "   70.66333333333333,\n",
       "   70.42166666666667,\n",
       "   70.945],\n",
       "  'val_verified_acc': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0],\n",
       "  'epsilon': [0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.0,\n",
       "   0.012,\n",
       "   0.024,\n",
       "   0.036,\n",
       "   0.048,\n",
       "   0.06,\n",
       "   0.072,\n",
       "   0.084,\n",
       "   0.096,\n",
       "   0.108,\n",
       "   0.12,\n",
       "   0.132,\n",
       "   0.144,\n",
       "   0.156,\n",
       "   0.168,\n",
       "   0.18,\n",
       "   0.192,\n",
       "   0.20400000000000001,\n",
       "   0.216,\n",
       "   0.22799999999999998,\n",
       "   0.24,\n",
       "   0.252,\n",
       "   0.264,\n",
       "   0.276,\n",
       "   0.288]})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sabr(model_sabr, train_dl, test_dl, device = device, num_epochs = 30, standard_epochs = 5, epsilon_schedule_length = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.4234, Acc: 86.62%, Verified: 0.00%\n",
      "  Val   - Loss: 0.1579, Acc: 95.13%, Verified: 0.00%\n",
      "Epoch 2/31, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.1330, Acc: 95.90%, Verified: 0.00%\n",
      "  Val   - Loss: 0.1171, Acc: 96.45%, Verified: 0.00%\n",
      "Epoch 3/31, ε=0.00000, IBP Weight=0.00\n",
      "  Train - Loss: 0.0951, Acc: 97.02%, Verified: 0.00%\n",
      "  Val   - Loss: 0.0937, Acc: 97.04%, Verified: 0.00%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_ibp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m31\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandard_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepsilon_schedule_length\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# train_sabr(model_sabr, train_dl, test_dl, device = device, num_epochs = 60, standard_epochs = 10, epsilon_schedule_length = 50)\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# train(model, train_dl, test_dl, device = device, num_epochs = 5)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/cs584_25/training_utils.py:663\u001b[39m, in \u001b[36mtrain_ibp\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, criterion, num_epochs, device, scheduler, verbose, start_epsilon, end_epsilon, epsilon_schedule_length, standard_epochs, ibp_weight_start, ibp_weight_end)\u001b[39m\n\u001b[32m    660\u001b[39m     ibp_correct = \u001b[32m0\u001b[39m\n\u001b[32m    662\u001b[39m \u001b[38;5;66;03m# Backward pass and optimize\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    664\u001b[39m optimizer.step()\n\u001b[32m    666\u001b[39m \u001b[38;5;66;03m# Track statistics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda/envs/torch/lib/python3.13/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda/envs/torch/lib/python3.13/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda/envs/torch/lib/python3.13/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train_ibp(model, train_dl, test_dl, device = device, num_epochs = 31, standard_epochs = 5, epsilon_schedule_length = 25)\n",
    "# train_sabr(model_sabr, train_dl, test_dl, device = device, num_epochs = 60, standard_epochs = 10, epsilon_schedule_length = 50)\n",
    "# train(model, train_dl, test_dl, device = device, num_epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard accuracy on clean test batch: 7.8125\n",
      "Standard accuracy on adversarial test batch: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IBP verified accuracy on test batch: 0.0\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(test_dl))\n",
    "x, y = x.to(device), y.to(device)\n",
    "print(\"Standard accuracy on clean test batch:\", batch_accuracy(model_sabr, x, y, device = device))\n",
    "x_adv = pgd_attack(model_sabr, x, y, epsilon = 0.3, step_size = 0.05, num_iterations = 40, device = device)\n",
    "print(\"Standard accuracy on adversarial test batch:\", batch_accuracy(model_sabr, x_adv, y, device = device))\n",
    "print(\"IBP verified accuracy on test batch:\", ibp_verified_batch_accuracy(IBPWrapper(model_sabr), x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ibp_verified_batch_accuracy(IBPWrapper(model), x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to project_networks/test.onnx\n",
      "PyTorch and ONNX model outputs match within tolerance!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True,\n",
       " array([[-0.5414923 , -0.7776395 ,  1.7545903 , ..., 13.2563715 ,\n",
       "         -2.0799277 ,  2.5294693 ],\n",
       "        [-1.3350446 , -1.2298107 , 11.889478  , ..., -1.8483633 ,\n",
       "         -2.4985616 , -5.8051505 ],\n",
       "        [-2.8744605 , 10.820565  , -1.4901669 , ..., -0.08323645,\n",
       "          0.70022815, -0.9620333 ],\n",
       "        ...,\n",
       "        [-1.1926395 , -0.9865389 , -2.3886838 , ...,  0.02875651,\n",
       "         -1.6081289 ,  7.770037  ],\n",
       "        [ 7.514521  , -2.7267783 , -0.71819985, ..., -1.4392903 ,\n",
       "         -0.31311888,  2.9348948 ],\n",
       "        [-3.401582  , -2.3115942 , -5.928955  , ..., -1.7363611 ,\n",
       "          0.12566383,  2.0006714 ]], dtype=float32),\n",
       " array([[-0.5414927 , -0.77764016,  1.75459   , ..., 13.256373  ,\n",
       "         -2.0799267 ,  2.5294697 ],\n",
       "        [-1.3350456 , -1.2298094 , 11.889477  , ..., -1.8483628 ,\n",
       "         -2.4985626 , -5.805151  ],\n",
       "        [-2.8744602 , 10.820564  , -1.4901669 , ..., -0.08323721,\n",
       "          0.70022863, -0.962033  ],\n",
       "        ...,\n",
       "        [-1.1926391 , -0.98653954, -2.3886824 , ...,  0.02875639,\n",
       "         -1.6081293 ,  7.770037  ],\n",
       "        [ 7.5145206 , -2.726778  , -0.71819973, ..., -1.4392906 ,\n",
       "         -0.31311828,  2.934896  ],\n",
       "        [-3.401583  , -2.3115952 , -5.928953  , ..., -1.73636   ,\n",
       "          0.12566358,  2.0006704 ]], dtype=float32))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_to_onnx(model, x, 'project_networks/test.onnx')\n",
    "verify_onnx_model(model, 'project_networks/test.onnx', x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
