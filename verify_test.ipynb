{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/apps/conda/cmxu/envs/autolipra/lib/python3.11/site-packages/torch/utils/cpp_extension.py:28: DeprecationWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html\n",
      "  from pkg_resources import packaging  # type: ignore[attr-defined]\n",
      "No CUDA runtime is found, using CUDA_HOME='/usr'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from src.common import Dataset, RavenMode\n",
    "from src.specLoader import get_specification, get_std\n",
    "from src.netLoader import get_net\n",
    "from src.adaptiveRavenBackend import AdaptiveRavenBackend\n",
    "from src.adaptiveRavenResult import AdaptiveRavenResultList\n",
    "from raven.src.config import mnist_data_transform\n",
    "import raven.src.config as config\n",
    "from auto_LiRPA.operators import BoundLinear, BoundConv\n",
    "import numpy as np\n",
    "from raven.src.network_conversion_helper import get_pytorch_net\n",
    "from auto_LiRPA import BoundedModule, PerturbationLpNorm, BoundedTensor\n",
    "from src.multinet_gurobi_certifier import MultiNetMILPTransformer\n",
    "\n",
    "from network_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "eps tensor tensor([0.1551, 0.1573, 0.1561])\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset.CIFAR10\n",
    "prop_count = 100\n",
    "count_per_prop = 1\n",
    "total_input_count = prop_count * count_per_prop\n",
    "eps = 8/255\n",
    "net_names = ['test']\n",
    "nets = ['project_networks/cifar10_cnn_2layer_w1.onnx']\n",
    "nets = [load_onnx_to_pytorch(a) for a in nets]\n",
    "images, labels, constraint_matrices, lbs, ubs = get_specification(dataset=dataset,\n",
    "                                                            raven_mode=RavenMode.UAP, \n",
    "                                                            count=total_input_count, nets=nets, eps=eps,\n",
    "                                                            dataloading_seed=1232,\n",
    "                                                            net_names=net_names,\n",
    "                                                            only_cutoff=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Property:\n",
    "    def __init__(self, inputs, labels, eps, constraint_matrices, lbs, ubs) -> None:\n",
    "        self.inputs = inputs\n",
    "        self.labels = labels\n",
    "        self.eps = eps\n",
    "        self.constraint_matrices = constraint_matrices\n",
    "        self.lbs = lbs\n",
    "        self.ubs = ubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_linear_coefs_biases(model, prop, device, input_name, final_name):\n",
    "    ptb = PerturbationLpNorm(norm = np.inf, x_L=prop.lbs, x_U=prop.ubs)\n",
    "    bounded_images = BoundedTensor(prop.inputs, ptb)\n",
    "    coef_dict = {final_name: [input_name]}\n",
    "    result = model.compute_bounds(x=(bounded_images,), method='CROWN-Optimized', C=prop.constraint_matrices,\n",
    "                                    bound_upper=False, return_A=True, needed_A_dict=coef_dict, \n",
    "                                    multiple_execution=False, execution_count=None, ptb=ptb, \n",
    "                                    unperturbed_images = prop.inputs)\n",
    "    lower_bnd, upper, A_dict = result\n",
    "    lA = A_dict[final_name][input_name]['lA']\n",
    "    lbias = A_dict[final_name][input_name]['lbias']\n",
    "    lA = torch.reshape(lA,(1, 9,-1))\n",
    "    return lA, lbias, lower_bnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def populate_names(model):\n",
    "    final_names = []\n",
    "    input_names = []\n",
    "    layer_names = []\n",
    "    i = 0\n",
    "    last_name = None\n",
    "    for node_name, node in model._modules.items():\n",
    "        if i == 0:\n",
    "            input_names.append(node_name)\n",
    "        i += 1\n",
    "        if type(node) in [BoundLinear, BoundConv]:\n",
    "            layer_names.append(node_name)\n",
    "            last_name = node_name\n",
    "    assert last_name is not None\n",
    "    final_names.append(node_name)\n",
    "    return input_names, layer_names, final_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (3): ReLU()\n",
       "  (4): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (6): ReLU()\n",
       "  (7): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (12): ReLU()\n",
       "  (13): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (14): ReLU()\n",
       "  (15): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.Sequential(*list(nets[0].modules())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphModule(\n",
       "  (0/Conv): Conv2d(3, 4, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (1/Relu): ReLU()\n",
       "  (2/Conv): Conv2d(4, 8, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (3/Relu): ReLU()\n",
       "  (4/Flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (5/Gemm): Linear(in_features=512, out_features=128, bias=True)\n",
       "  (6/Relu): ReLU()\n",
       "  (7/Gemm): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (8/Relu): ReLU()\n",
       "  (9/Gemm): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (10/Relu): ReLU()\n",
       "  (11/Gemm): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (12/Relu): ReLU()\n",
       "  (13/Gemm): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (14/Relu): ReLU()\n",
       "  (15/Gemm): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def g2s(model):\n",
    "    return torch.nn.Sequential(*list(nets[0].modules())[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'GraphModule' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m models = []\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m nets:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     torch_net = \u001b[43mget_pytorch_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_last_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_linear\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     models.append(BoundedModule(torch_net, (prop.inputs), bound_opts={}))\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m net \u001b[38;5;129;01min\u001b[39;00m models:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/cs584_25/raven/src/network_conversion_helper.py:81\u001b[39m, in \u001b[36mget_pytorch_net\u001b[39m\u001b[34m(model, remove_last_layer, all_linear)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_pytorch_net\u001b[39m(model, remove_last_layer, all_linear):\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m     converted_model = \u001b[43mconvert_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_net\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_last_layer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mremove_last_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_linear\u001b[49m\u001b[43m=\u001b[49m\u001b[43mall_linear\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m converted_model\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/cs584_25/raven/src/network_conversion_helper.py:71\u001b[39m, in \u001b[36mconvert_model\u001b[39m\u001b[34m(parsed_net, remove_last_layer, all_linear)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert_model\u001b[39m(parsed_net, remove_last_layer=\u001b[38;5;28;01mTrue\u001b[39;00m, all_linear=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mTransformedNet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparsed_net\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_last_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_linear\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/share/cs584_25/raven/src/network_conversion_helper.py:31\u001b[39m, in \u001b[36mTransformedNet.__init__\u001b[39m\u001b[34m(self, layers, ignore_last_layer, all_linear)\u001b[39m\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m all_linear:\n\u001b[32m     30\u001b[39m     constructed_layers.append(Flatten(start_dim=\u001b[32m1\u001b[39m))\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayers\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43mLayerType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLinear\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlinear_layer_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconv_layer_count\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: 'GraphModule' object is not iterable"
     ]
    }
   ],
   "source": [
    "for i in range(prop_count):\n",
    "    start = i * count_per_prop\n",
    "    end = start + count_per_prop\n",
    "    prop_images, prop_labels, prop_constraint_matrices = images[start:end], labels[start:end], constraint_matrices[start:end]\n",
    "    prop_lbs, prop_ubs = lbs[start:end], ubs[start:end]\n",
    "    prop = Property(inputs=prop_images, labels=prop_labels, \n",
    "                    eps=eps / get_std(dataset=dataset, transform=True),\n",
    "                    constraint_matrices=prop_constraint_matrices, lbs=prop_lbs, ubs=prop_ubs)\n",
    "    final_names = []\n",
    "    input_names = []\n",
    "    models = []\n",
    "    for net in nets:\n",
    "        torch_net = get_pytorch_net(model=net, remove_last_layer=False, all_linear=False)\n",
    "        models.append(BoundedModule(torch_net, (prop.inputs), bound_opts={}))\n",
    "    for net in models:\n",
    "        ins, _, fns = populate_names(net)\n",
    "        final_names.append(fns[0])\n",
    "        input_names.append(ins[0])\n",
    "    get_linear_coefs_biases(models[0], prop)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autolipra",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
